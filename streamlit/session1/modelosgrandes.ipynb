{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: 202316187 (sergom2). Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xm3rqyr8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">EfficientNet_B4_Model</strong> at: <a href='https://wandb.ai/sergom2/ML2-img-class/runs/xm3rqyr8' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class/runs/xm3rqyr8</a><br/> View project at: <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240413_111759-xm3rqyr8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xm3rqyr8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sergi\\OneDrive\\Escritorio\\MBD\\Machine Learning 2\\Practicas_DeepLearning_2024\\streamlit\\session1\\wandb\\run-20240413_112013-9w9wt6bl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergom2/ML2-img-class/runs/9w9wt6bl' target=\"_blank\">EfficientNet_B4_Model</a></strong> to <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergom2/ML2-img-class/runs/9w9wt6bl' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class/runs/9w9wt6bl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\anaconda3\\envs\\ML2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sergi\\anaconda3\\envs\\ML2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to C:\\Users\\sergi/.cache\\torch\\hub\\checkpoints\\efficientnet_b4_rwightman-23ab8bcd.pth\n",
      "100%|██████████| 74.5M/74.5M [00:02<00:00, 26.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Loss: 2.709487199783325\n",
      "Epoch 1, Batch 11, Loss: 2.6965267658233643\n",
      "Epoch 1, Batch 21, Loss: 2.6925296783447266\n",
      "Epoch 1, Batch 31, Loss: 2.657621383666992\n",
      "Epoch 1, Batch 41, Loss: 2.644847869873047\n",
      "Estimated time left: 3478.87 minutes\n",
      "Epoch 1/20, Train Loss: 2.6762, Train Accuracy: 0.1759, Val Loss: 2.6410, Val Accuracy: 0.3433\n",
      "Epoch 2, Batch 1, Loss: 2.635890007019043\n",
      "Epoch 2, Batch 11, Loss: 2.6136369705200195\n",
      "Epoch 2, Batch 21, Loss: 2.5777878761291504\n",
      "Epoch 2, Batch 31, Loss: 2.562704563140869\n",
      "Epoch 2, Batch 41, Loss: 2.5257136821746826\n",
      "Estimated time left: 3057.29 minutes\n",
      "Epoch 2/20, Train Loss: 2.5734, Train Accuracy: 0.4328, Val Loss: 2.4938, Val Accuracy: 0.5927\n",
      "Epoch 3, Batch 1, Loss: 2.5089340209960938\n",
      "Epoch 3, Batch 11, Loss: 2.4094855785369873\n",
      "Epoch 3, Batch 21, Loss: 2.3960065841674805\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# Configuración inicial de wandb\n",
    "wandb.init(project=\"ML2-img-class\", name=\"EfficientNet_B4_Model\", config={\n",
    "    \"learning_rate\": 0.00005,\n",
    "    \"architecture\": \"efficientnet_b4\",\n",
    "    \"dataset\": \"Tu Dataset Local\",\n",
    "    \"unfreezed_layers\": 15,\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 128\n",
    "})\n",
    "config = wandb.config\n",
    "\n",
    "# Transformaciones\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(380),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(450),\n",
    "    transforms.CenterCrop(380),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Carga de datos\n",
    "train_data = datasets.ImageFolder('C:/Users/sergi/OneDrive/Escritorio/MBD/Machine Learning 2/Practicas_DeepLearning_2024/03TransferLearning/dataset/training', transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder('C:/Users/sergi/OneDrive/Escritorio/MBD/Machine Learning 2/Practicas_DeepLearning_2024/03TransferLearning/dataset/validation', transform=valid_transforms)\n",
    "train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "# Cargar el modelo preentrenado\n",
    "model = models.efficientnet_b4(pretrained=True)\n",
    "\n",
    "# Descongelar las últimas 15 capas\n",
    "for child in list(model.children())[-config.unfreezed_layers:]:\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Cambiar la capa final para 15 clases\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 15)\n",
    "\n",
    "# Criterio de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        start_time_epoch = time.time()\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += (outputs.argmax(1) == labels).float().mean().item() * inputs.size(0)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {loss.item()}')\n",
    "        \n",
    "        epoch_duration = time.time() - start_time_epoch\n",
    "        estimated_time_left = epoch_duration * (num_epochs - epoch - 1)\n",
    "        print(f'Estimated time left: {estimated_time_left/60:.2f} minutes')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = running_accuracy / len(train_loader.dataset)\n",
    "        \n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_accuracy += (outputs.argmax(1) == labels).float().mean().item() * inputs.size(0)\n",
    "                \n",
    "        val_epoch_loss = val_running_loss / len(valid_loader.dataset)\n",
    "        val_epoch_accuracy = val_running_accuracy / len(valid_loader.dataset)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to W&B\n",
    "        wandb.log({\n",
    "            'train_loss': epoch_loss, \n",
    "            'train_accuracy': epoch_accuracy,\n",
    "            'val_loss': val_epoch_loss, \n",
    "            'val_accuracy': val_epoch_accuracy\n",
    "        })\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_accuracy:.4f}')\n",
    "               \n",
    "    return model\n",
    "\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=config.epochs)\n",
    "torch.save(model.state_dict(), 'efficientnet_b4_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3j58oqpt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DenseNet201_Model</strong> at: <a href='https://wandb.ai/sergom2/ML2-img-class/runs/3j58oqpt' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class/runs/3j58oqpt</a><br/> View project at: <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240413_192053-3j58oqpt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3j58oqpt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sergi\\OneDrive\\Escritorio\\MBD\\Machine Learning 2\\Practicas_DeepLearning_2024\\streamlit\\session1\\wandb\\run-20240413_193009-z7tqqxb4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergom2/ML2-img-class/runs/z7tqqxb4' target=\"_blank\">DenseNet201_Model</a></strong> to <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergom2/ML2-img-class/runs/z7tqqxb4' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class/runs/z7tqqxb4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\anaconda3\\envs\\ML2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sergi\\anaconda3\\envs\\ML2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Loss: 2.7377614974975586\n",
      "Epoch 1, Batch 11, Loss: 2.627082109451294\n",
      "Epoch 1, Batch 21, Loss: 2.626823902130127\n",
      "Epoch 1, Batch 31, Loss: 2.6241648197174072\n",
      "Epoch 1, Batch 41, Loss: 2.454120635986328\n",
      "Estimated time left: 55.87 minutes\n",
      "Epoch 1/10, Train Loss: 2.5566, Train Accuracy: 0.1843, Val Loss: 2.4553, Val Accuracy: 0.2353\n",
      "Epoch 2, Batch 1, Loss: 2.4415924549102783\n",
      "Epoch 2, Batch 11, Loss: 2.320944309234619\n",
      "Epoch 2, Batch 21, Loss: 2.231729745864868\n",
      "Epoch 2, Batch 31, Loss: 2.227280378341675\n",
      "Epoch 2, Batch 41, Loss: 2.1489882469177246\n",
      "Estimated time left: 49.84 minutes\n",
      "Epoch 2/10, Train Loss: 2.2496, Train Accuracy: 0.3963, Val Loss: 2.1614, Val Accuracy: 0.4153\n",
      "Epoch 3, Batch 1, Loss: 2.1050400733947754\n",
      "Epoch 3, Batch 11, Loss: 2.0685713291168213\n",
      "Epoch 3, Batch 21, Loss: 2.0572926998138428\n",
      "Epoch 3, Batch 31, Loss: 1.914212942123413\n",
      "Epoch 3, Batch 41, Loss: 2.0579891204833984\n",
      "Estimated time left: 42.00 minutes\n",
      "Epoch 3/10, Train Loss: 2.0094, Train Accuracy: 0.5216, Val Loss: 1.9117, Val Accuracy: 0.5513\n",
      "Epoch 4, Batch 1, Loss: 1.9286468029022217\n",
      "Epoch 4, Batch 11, Loss: 1.8949003219604492\n",
      "Epoch 4, Batch 21, Loss: 1.78119957447052\n",
      "Epoch 4, Batch 31, Loss: 1.9310942888259888\n",
      "Epoch 4, Batch 41, Loss: 1.8149333000183105\n",
      "Estimated time left: 39.03 minutes\n",
      "Epoch 4/10, Train Loss: 1.8043, Train Accuracy: 0.6090, Val Loss: 1.7139, Val Accuracy: 0.6347\n",
      "Epoch 5, Batch 1, Loss: 1.690405249595642\n",
      "Epoch 5, Batch 11, Loss: 1.6357741355895996\n",
      "Epoch 5, Batch 21, Loss: 1.7695618867874146\n",
      "Epoch 5, Batch 31, Loss: 1.6506227254867554\n",
      "Epoch 5, Batch 41, Loss: 1.5275781154632568\n",
      "Estimated time left: 32.69 minutes\n",
      "Epoch 5/10, Train Loss: 1.6320, Train Accuracy: 0.6854, Val Loss: 1.5408, Val Accuracy: 0.6633\n",
      "Epoch 6, Batch 1, Loss: 1.5564510822296143\n",
      "Epoch 6, Batch 11, Loss: 1.5118860006332397\n",
      "Epoch 6, Batch 21, Loss: 1.4023703336715698\n",
      "Epoch 6, Batch 31, Loss: 1.4923597574234009\n",
      "Epoch 6, Batch 41, Loss: 1.4724042415618896\n",
      "Estimated time left: 27.24 minutes\n",
      "Epoch 6/10, Train Loss: 1.4980, Train Accuracy: 0.7136, Val Loss: 1.3868, Val Accuracy: 0.7307\n",
      "Epoch 7, Batch 1, Loss: 1.3726606369018555\n",
      "Epoch 7, Batch 11, Loss: 1.3162038326263428\n",
      "Epoch 7, Batch 21, Loss: 1.420555591583252\n",
      "Epoch 7, Batch 31, Loss: 1.254910945892334\n",
      "Epoch 7, Batch 41, Loss: 1.3302305936813354\n",
      "Estimated time left: 19.35 minutes\n",
      "Epoch 7/10, Train Loss: 1.3671, Train Accuracy: 0.7467, Val Loss: 1.2564, Val Accuracy: 0.7833\n",
      "Epoch 8, Batch 1, Loss: 1.3613111972808838\n",
      "Epoch 8, Batch 11, Loss: 1.3194947242736816\n",
      "Epoch 8, Batch 21, Loss: 1.2241339683532715\n",
      "Epoch 8, Batch 31, Loss: 1.3344297409057617\n",
      "Epoch 8, Batch 41, Loss: 1.3892772197723389\n",
      "Estimated time left: 11.69 minutes\n",
      "Epoch 8/10, Train Loss: 1.3107, Train Accuracy: 0.7591, Val Loss: 1.2534, Val Accuracy: 0.7827\n",
      "Epoch 9, Batch 1, Loss: 1.1813007593154907\n",
      "Epoch 9, Batch 11, Loss: 1.346293568611145\n",
      "Epoch 9, Batch 21, Loss: 1.3735712766647339\n",
      "Epoch 9, Batch 31, Loss: 1.3486295938491821\n",
      "Epoch 9, Batch 41, Loss: 1.3295514583587646\n",
      "Estimated time left: 6.93 minutes\n",
      "Epoch 9/10, Train Loss: 1.2960, Train Accuracy: 0.7688, Val Loss: 1.2466, Val Accuracy: 0.7833\n",
      "Epoch 10, Batch 1, Loss: 1.31513512134552\n",
      "Epoch 10, Batch 11, Loss: 1.1676068305969238\n",
      "Epoch 10, Batch 21, Loss: 1.2900302410125732\n",
      "Epoch 10, Batch 31, Loss: 1.1640877723693848\n",
      "Epoch 10, Batch 41, Loss: 1.220111608505249\n",
      "Estimated time left: 0.00 minutes\n",
      "Epoch 10/10, Train Loss: 1.2779, Train Accuracy: 0.7722, Val Loss: 1.2232, Val Accuracy: 0.7807\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# Configuración inicial de wandb\n",
    "wandb.init(project=\"ML2-img-class\", name=\"DenseNet201_Model\", config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"densenet201\",\n",
    "    \"dataset\": \"Tu Dataset Local\",\n",
    "    \"unfreezed_layers\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 64\n",
    "})\n",
    "config = wandb.config\n",
    "\n",
    "# Transformaciones\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Carga de datos\n",
    "train_data = datasets.ImageFolder('C:/Users/sergi/OneDrive/Escritorio/MBD/Machine Learning 2/Practicas_DeepLearning_2024/03TransferLearning/dataset/training', transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder('C:/Users/sergi/OneDrive/Escritorio/MBD/Machine Learning 2/Practicas_DeepLearning_2024/03TransferLearning/dataset/validation', transform=valid_transforms)\n",
    "train_loader = DataLoader(train_data, batch_size=config.batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "# Cargar el modelo preentrenado\n",
    "model = models.densenet201(pretrained=True)\n",
    "\n",
    "# Descongelar las últimas 15 capas\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 15)  # Cambiado para adaptar a 15 clases\n",
    "\n",
    "# Criterio de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        start_time_epoch = time.time()\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += (outputs.argmax(1) == labels).float().mean().item() * inputs.size(0)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {loss.item()}')\n",
    "        \n",
    "        epoch_duration = time.time() - start_time_epoch\n",
    "        estimated_time_left = epoch_duration * (num_epochs - epoch - 1)\n",
    "        print(f'Estimated time left: {estimated_time_left/60:.2f} minutes')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = running_accuracy / len(train_loader.dataset)\n",
    "        \n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_accuracy += (outputs.argmax(1) == labels).float().mean().item() * inputs.size(0)\n",
    "                \n",
    "        val_epoch_loss = val_running_loss / len(valid_loader.dataset)\n",
    "        val_epoch_accuracy = val_running_accuracy / len(valid_loader.dataset)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log to W&B\n",
    "        wandb.log({\n",
    "            'train_loss': epoch_loss, \n",
    "            'train_accuracy': epoch_accuracy,\n",
    "            'val_loss': val_epoch_loss, \n",
    "            'val_accuracy': val_epoch_accuracy\n",
    "        })\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_accuracy:.4f}')\n",
    "               \n",
    "    return model\n",
    "\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=config.epochs)\n",
    "torch.save(model.state_dict(), 'densenet201_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:eq5z7220) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResNet121_Model</strong> at: <a href='https://wandb.ai/sergom2/ML2-img-class/runs/eq5z7220' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class/runs/eq5z7220</a><br/> View project at: <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240413_205744-eq5z7220\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:eq5z7220). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sergi\\OneDrive\\Escritorio\\MBD\\Machine Learning 2\\Practicas_DeepLearning_2024\\streamlit\\session1\\wandb\\run-20240413_210226-3vvepedc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sergom2/ML2-img-class/runs/3vvepedc' target=\"_blank\">ResNet121_Model</a></strong> to <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sergom2/ML2-img-class' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sergom2/ML2-img-class/runs/3vvepedc' target=\"_blank\">https://wandb.ai/sergom2/ML2-img-class/runs/3vvepedc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\anaconda3\\envs\\ML2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sergi\\anaconda3\\envs\\ML2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to C:\\Users\\sergi/.cache\\torch\\hub\\checkpoints\\resnet152-394f9c45.pth\n",
      "100%|██████████| 230M/230M [00:05<00:00, 40.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1, Lote 1, Pérdida del Lote: 2.8154356479644775\n",
      "Época 1, Lote 11, Pérdida del Lote: 1.1189895868301392\n",
      "Época 1, Lote 21, Pérdida del Lote: 0.6396958231925964\n",
      "Tiempo estimado restante: 543.07 minutos\n",
      "Epoch 1/10, Train Loss: 1.2160, Train Accuracy: 0.6888, Val Loss: 0.3733, Val Accuracy: 0.8920\n",
      "Época 2, Lote 1, Pérdida del Lote: 0.4634690582752228\n",
      "Época 2, Lote 11, Pérdida del Lote: 0.33883050084114075\n",
      "Época 2, Lote 21, Pérdida del Lote: 0.35004615783691406\n",
      "Tiempo estimado restante: 503.67 minutos\n",
      "Epoch 2/10, Train Loss: 0.3943, Train Accuracy: 0.8697, Val Loss: 0.2633, Val Accuracy: 0.9127\n",
      "Época 3, Lote 1, Pérdida del Lote: 0.3483724594116211\n",
      "Época 3, Lote 11, Pérdida del Lote: 0.236895352602005\n",
      "Época 3, Lote 21, Pérdida del Lote: 0.2205365151166916\n",
      "Tiempo estimado restante: 455.03 minutos\n",
      "Epoch 3/10, Train Loss: 0.2841, Train Accuracy: 0.9072, Val Loss: 0.2291, Val Accuracy: 0.9273\n",
      "Época 4, Lote 1, Pérdida del Lote: 0.19069203734397888\n",
      "Época 4, Lote 11, Pérdida del Lote: 0.2605493664741516\n",
      "Época 4, Lote 21, Pérdida del Lote: 0.24536177515983582\n",
      "Tiempo estimado restante: 422.26 minutos\n",
      "Epoch 4/10, Train Loss: 0.2634, Train Accuracy: 0.9203, Val Loss: 0.1899, Val Accuracy: 0.9387\n",
      "Época 5, Lote 1, Pérdida del Lote: 0.3563288152217865\n",
      "Época 5, Lote 11, Pérdida del Lote: 0.19196534156799316\n",
      "Época 5, Lote 21, Pérdida del Lote: 0.25947704911231995\n",
      "Tiempo estimado restante: 353.50 minutos\n",
      "Epoch 5/10, Train Loss: 0.2833, Train Accuracy: 0.9079, Val Loss: 0.1924, Val Accuracy: 0.9387\n",
      "Época 6, Lote 1, Pérdida del Lote: 0.24795779585838318\n",
      "Época 6, Lote 11, Pérdida del Lote: 0.17084380984306335\n",
      "Época 6, Lote 21, Pérdida del Lote: 0.1994684636592865\n",
      "Tiempo estimado restante: 286.35 minutos\n",
      "Epoch 6/10, Train Loss: 0.2367, Train Accuracy: 0.9250, Val Loss: 0.2165, Val Accuracy: 0.9227\n",
      "Época 7, Lote 1, Pérdida del Lote: 0.2900739908218384\n",
      "Época 7, Lote 11, Pérdida del Lote: 0.19959843158721924\n",
      "Época 7, Lote 21, Pérdida del Lote: 0.20962680876255035\n",
      "Tiempo estimado restante: 215.21 minutos\n",
      "Epoch 7/10, Train Loss: 0.2106, Train Accuracy: 0.9310, Val Loss: 0.2140, Val Accuracy: 0.9320\n",
      "Época 8, Lote 1, Pérdida del Lote: 0.18158452212810516\n",
      "Época 8, Lote 11, Pérdida del Lote: 0.30961453914642334\n",
      "Época 8, Lote 21, Pérdida del Lote: 0.19450047612190247\n",
      "Tiempo estimado restante: 141.76 minutos\n",
      "Epoch 8/10, Train Loss: 0.2017, Train Accuracy: 0.9387, Val Loss: 0.1830, Val Accuracy: 0.9333\n",
      "Época 9, Lote 1, Pérdida del Lote: 0.14780212938785553\n",
      "Época 9, Lote 11, Pérdida del Lote: 0.12875916063785553\n",
      "Época 9, Lote 21, Pérdida del Lote: 0.08521434664726257\n",
      "Tiempo estimado restante: 71.03 minutos\n",
      "Epoch 9/10, Train Loss: 0.1525, Train Accuracy: 0.9511, Val Loss: 0.1306, Val Accuracy: 0.9573\n",
      "Época 10, Lote 1, Pérdida del Lote: 0.1053936779499054\n",
      "Época 10, Lote 11, Pérdida del Lote: 0.17012162506580353\n",
      "Época 10, Lote 21, Pérdida del Lote: 0.13033480942249298\n",
      "Tiempo estimado restante: 0.00 minutos\n",
      "Epoch 10/10, Train Loss: 0.1379, Train Accuracy: 0.9554, Val Loss: 0.1238, Val Accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "# Configuración inicial de wandb\n",
    "wandb.init(project=\"ML2-img-class\", name=\"ResNet121_Model\", config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"architecture\": \"resnet152\",\n",
    "    \"dataset\": \"Tu Dataset Local\",\n",
    "    \"unfreezed_layers\": 10,  # Número de capas a descongelar\n",
    "    \"epochs\": 10,\n",
    "})\n",
    "config = wandb.config\n",
    "\n",
    "# Transformaciones\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Carga de datos\n",
    "train_data = datasets.ImageFolder('C:/Users/sergi/OneDrive/Escritorio/MBD/Machine Learning 2/Practicas_DeepLearning_2024/03TransferLearning/dataset/training', transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder('C:/Users/sergi/OneDrive/Escritorio/MBD/Machine Learning 2/Practicas_DeepLearning_2024/03TransferLearning/dataset/validation', transform=valid_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=128, shuffle=False)\n",
    "\n",
    "# Cargar el modelo preentrenado ResNet152\n",
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "# Descongelar las últimas 10 capas\n",
    "children = list(model.children())\n",
    "num_children = len(children)\n",
    "for i in range(num_children - 10, num_children):\n",
    "    for param in children[i].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(train_data.classes))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)\n",
    "\n",
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        \n",
    "        start_time_epoch = time.time()  # Tiempo de inicio de la época\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
    "            \n",
    "            if i % 10 == 0:  # Imprime cada 10 lotes\n",
    "                print(f'Época {epoch+1}, Lote {i+1}, Pérdida del Lote: {loss.item()}')\n",
    "        \n",
    "        end_time_epoch = time.time()  # Tiempo al final de la época\n",
    "        epoch_duration = end_time_epoch - start_time_epoch\n",
    "        estimated_time_left = epoch_duration * (num_epochs - epoch - 1)\n",
    "        print(f\"Tiempo estimado restante: {estimated_time_left/60:.2f} minutos\")\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = running_accuracy / len(train_loader.dataset)\n",
    "        \n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_accuracy += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
    "                \n",
    "        val_epoch_loss = val_running_loss / len(valid_loader.dataset)\n",
    "        val_epoch_accuracy = val_running_accuracy / len(valid_loader.dataset)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log a W&B\n",
    "        wandb.log({'train_loss': epoch_loss, 'train_accuracy': epoch_accuracy,\n",
    "                   'val_loss': val_epoch_loss, 'val_accuracy': val_epoch_accuracy})\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_accuracy:.4f}')\n",
    "               \n",
    "    return model\n",
    "\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=config.epochs)\n",
    "torch.save(model.state_dict(), 'resnet152_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
